<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on 미래사회와 창의혁신인재</title>
    <link>https://ownogatari.xyz/posts/</link>
    <description>Recent content in Posts on 미래사회와 창의혁신인재</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 19 Dec 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://ownogatari.xyz/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>SDD</title>
      <link>https://ownogatari.xyz/posts/sdd/</link>
      <pubDate>Tue, 19 Dec 2023 00:00:00 +0000</pubDate>
      
      <guid>https://ownogatari.xyz/posts/sdd/</guid>
      <description>1. overview 1.1 objective multiple scale에 대해 다뤄 보자. (큰 물체, 작은 물체) \(\Rightarrow\) 장점: low resolution에 대한 문제를 해결 \(\Rightarrow\) 방법: 여러 개의 conv layer 도입
different shape에 대해 다뤄 보자. (박스 형태, 2:1, 1:1) \(\Rightarrow\) 장점: 다양한 형태의 객체 검출 \(\Rightarrow\) 방법: 박스 형태 다양하게
1.2 background YOLO YOLO 같은 경우 feature map이 \(7\times7\)짜리 1개이다. box개수는 각 cell마다 2개 있어서 총 98개이다.
2. main 2.1 architecture pretrained model + convolutional layer 논문에서는 VGG를 pretrained model로 사용</description>
    </item>
    
    <item>
      <title>R-FCN</title>
      <link>https://ownogatari.xyz/posts/r-fcn/</link>
      <pubDate>Thu, 23 Nov 2023 00:00:00 +0000</pubDate>
      
      <guid>https://ownogatari.xyz/posts/r-fcn/</guid>
      <description>1. overview 1.1 objective translation invariance 문제를 해결해보자. 모델을 fully convolutional 하게 만들어보자. 1.2 Background translational invariance vs translational variance translational invariance의 정의 positional invariance(translation invariance): 위치가 변하여도 결과가 똑같아야함 = 위치가 영향을 주지 않음 image classification에서의 주요 과제
cnn은 translational invaraince하다.
weight sharing convolutiona filter를 활용한 계산은 원래 translational equivariance(translational variance)함. 층이 깊어질 수록 tralational invariance가 됨. 그 이유는 계속 같은 필터를 써서(weight sharing) max pooling max pooling 역시 translational invariance한 연산 cnn은 어떤 위치에 사물이 있어도 잘 classify한다.</description>
    </item>
    
    <item>
      <title>Ddpg</title>
      <link>https://ownogatari.xyz/posts/ddpg/</link>
      <pubDate>Sat, 23 Sep 2023 00:53:01 +0900</pubDate>
      
      <guid>https://ownogatari.xyz/posts/ddpg/</guid>
      <description>0. BackGround observation: \(x_t\)
state: \(s_t\)
state: \(a_t\)
reward: \(r_t\)
policy: \(\pi, \ \ S \to P(A)\)
transition dynamics : \(p(s_{t+1} \mid s_t,a_t)\)
discounted future reward : \(R_T = \sum_{i=t}^{T}\gamma^{(i-t)}r(s_i,a_i)\)
objective function: \(E_{r_i,s_i \sim E, a_i \sim \pi}[R_1]\)
\(Q^{\pi}(s_t,a_t) = E_{r_i\geq t, s_i &amp;gt;t \sim E , a_i &amp;gt; t \sim \pi}[R_t \mid s_t, a_t]\)
\(Q^{\pi}(s_t,a_t) = E_{r_t,s_{t+1} \sim E} [r(s_t,a_t)+ \gamma E_{a_{t+1} \sim \pi} [Q^{\pi}(s_{t+1}, a_{t+1})]]\)
\(Q^{\mu}(s_t,a_t) = E_{r_t,s_{t+1} \sim E} [r(s_t,a_t)+ \gamma Q^{\mu}(s_{t+1}, \mu(s_{t+1}))]\)</description>
    </item>
    
  </channel>
</rss>
