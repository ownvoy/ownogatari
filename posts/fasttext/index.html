<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>FastText | 미래사회와 창의혁신인재</title>
<meta name="keywords" content="">
<meta name="description" content="1. overview 1.1 objective 단어를 형태소의 측면에서 표현해보자.
1.2 background 1.2.1 형태소적 접근 기존의 단어 표현은 하나의 단어당 하나의 벡터로 이루어졌다. 하나의 단어를 여러 형태소의 벡터로 표현해보자. 먹음에 대해서 먹기, 먹이, 먹는, 먹다, 먹었음, 먹었다 등 여러 형태가 나타날 수 있다. 그러나, 훈련 데이터에는 모든 형태가 등장하지 않는다. 그렇게 되면, 등장하지 않는 단어에 대해서representation이 떨어질 수 있다. 만약 형태소로 접근한다면, -기, -이, -는의 형태는 다른 단어들에서 볼 수 있다. 즉, 먹었음이 훈련데이터에 없다해도, 먹-, -었-, -음의 합으로 표현할 수 있다.">
<meta name="author" content="">
<link rel="canonical" href="https://ownogatari.xyz/posts/fasttext/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.5cfc680b1eeaeef9efbced92d46c2a9e876b72ee14fba85846afc4cff9e6e6f8.css" integrity="sha256-XPxoCx7q7vnvvO2S1Gwqnodrcu4U&#43;6hYRq/Ez/nm5vg=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://ownogatari.xyz/images/favicon/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://ownogatari.xyz/images/favicon/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://ownogatari.xyz/images/favicon/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://ownogatari.xyz/images/favicon/apple-touch-icon.png">
<link rel="mask-icon" href="https://ownogatari.xyz/images/favicon/apple-touch-icon.png">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="FastText" />
<meta property="og:description" content="1. overview 1.1 objective 단어를 형태소의 측면에서 표현해보자.
1.2 background 1.2.1 형태소적 접근 기존의 단어 표현은 하나의 단어당 하나의 벡터로 이루어졌다. 하나의 단어를 여러 형태소의 벡터로 표현해보자. 먹음에 대해서 먹기, 먹이, 먹는, 먹다, 먹었음, 먹었다 등 여러 형태가 나타날 수 있다. 그러나, 훈련 데이터에는 모든 형태가 등장하지 않는다. 그렇게 되면, 등장하지 않는 단어에 대해서representation이 떨어질 수 있다. 만약 형태소로 접근한다면, -기, -이, -는의 형태는 다른 단어들에서 볼 수 있다. 즉, 먹었음이 훈련데이터에 없다해도, 먹-, -었-, -음의 합으로 표현할 수 있다." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://ownogatari.xyz/posts/fasttext/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-12T15:48:20+09:00" />
<meta property="article:modified_time" content="2024-01-12T15:48:20+09:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="FastText"/>
<meta name="twitter:description" content="1. overview 1.1 objective 단어를 형태소의 측면에서 표현해보자.
1.2 background 1.2.1 형태소적 접근 기존의 단어 표현은 하나의 단어당 하나의 벡터로 이루어졌다. 하나의 단어를 여러 형태소의 벡터로 표현해보자. 먹음에 대해서 먹기, 먹이, 먹는, 먹다, 먹었음, 먹었다 등 여러 형태가 나타날 수 있다. 그러나, 훈련 데이터에는 모든 형태가 등장하지 않는다. 그렇게 되면, 등장하지 않는 단어에 대해서representation이 떨어질 수 있다. 만약 형태소로 접근한다면, -기, -이, -는의 형태는 다른 단어들에서 볼 수 있다. 즉, 먹었음이 훈련데이터에 없다해도, 먹-, -었-, -음의 합으로 표현할 수 있다."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://ownogatari.xyz/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "FastText",
      "item": "https://ownogatari.xyz/posts/fasttext/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "FastText",
  "name": "FastText",
  "description": "1. overview 1.1 objective 단어를 형태소의 측면에서 표현해보자.\n1.2 background 1.2.1 형태소적 접근 기존의 단어 표현은 하나의 단어당 하나의 벡터로 이루어졌다. 하나의 단어를 여러 형태소의 벡터로 표현해보자. 먹음에 대해서 먹기, 먹이, 먹는, 먹다, 먹었음, 먹었다 등 여러 형태가 나타날 수 있다. 그러나, 훈련 데이터에는 모든 형태가 등장하지 않는다. 그렇게 되면, 등장하지 않는 단어에 대해서representation이 떨어질 수 있다. 만약 형태소로 접근한다면, -기, -이, -는의 형태는 다른 단어들에서 볼 수 있다. 즉, 먹었음이 훈련데이터에 없다해도, 먹-, -었-, -음의 합으로 표현할 수 있다.",
  "keywords": [
    
  ],
  "articleBody": "1. overview 1.1 objective 단어를 형태소의 측면에서 표현해보자.\n1.2 background 1.2.1 형태소적 접근 기존의 단어 표현은 하나의 단어당 하나의 벡터로 이루어졌다. 하나의 단어를 여러 형태소의 벡터로 표현해보자. 먹음에 대해서 먹기, 먹이, 먹는, 먹다, 먹었음, 먹었다 등 여러 형태가 나타날 수 있다. 그러나, 훈련 데이터에는 모든 형태가 등장하지 않는다. 그렇게 되면, 등장하지 않는 단어에 대해서representation이 떨어질 수 있다. 만약 형태소로 접근한다면, -기, -이, -는의 형태는 다른 단어들에서 볼 수 있다. 즉, 먹었음이 훈련데이터에 없다해도, 먹-, -었-, -음의 합으로 표현할 수 있다. 1.2.2 Skip Gram skipgram: 하나의 단어가 주어지면, 주변의 단어를 맞추는 것.\n데이터가 주어졌을 때, 아래 식을 최대화하는 것이 목적.\n$$\\sum_{t=1}^{T}\\sum_{c\\in{\\cal C}{t}}\\log p(w{c} \\ | \\ w_{t})$$\n확률 \\(p\\)는 softmax로 표현 될 수 있다.\n$$p(w_{c}\\mid w_{t})=\\frac{e^{s(w_{t},w_{c})}}{\\sum_{j=1}^{W}e^{s(w_{t},j)}}$$\n\\(s(w_t,w_c)\\)는 \\(w_t\\)와 \\(w_c\\)의 유사도를 구하는 함수이다.\n$$s(w_{t},{w}{c}),=,{\\mathbf{u}}{w_{t}}^{\\mathsf{T}}{\\mathbf{v}}{w{c}}$$\n2. main general model + subword model\n2.1 architecture 2.1.1 General model 변형 skipgram을 사용한다.\nBinary log loss with negative sampling 기존의 skipgram은 Softmax log loss를 사용한다. 이렇게 되면, \\(w_t\\)에 대해서 하나의 \\(w_c\\)를 예측하는 것으로 학습이 된다.\n여러 개의 \\(w_c\\)를 예측하기 위해서는 \\(c\\)마다 binary class 예측을 해야한다. 따라서, loss를 binary loss로 바꿔준다.\n$$\\log\\left(1+e^{-s(w_{t},,w_{c})}\\right)+\\sum_{n\\in\\mathcal{N}{t.c}}\\log\\left(1+e^{s(w{t},,n)}\\right)$$\n첫번째 term: \\(w_t\\)와 \\(w_c\\)의 유사도를 비슷하게 만들도록 학습 두번째 term: \\(w_t\\)와 \\(n\\)의 유사도를 다르게 만들도록 학습 2.1.2 Subword model 우선 where이라는 단어가 있을 때, 이를 \\(\u003c where \u003e\\)로 바꿔준다. 이 때, \u003c와 \u003e는 경계를 나타낸다. \\(\\leftarrow\\) 형태소는 하나의 단어를 기준으로 하기 때문에 필요하다.\n그 후 character \\(n\\)-gram을 도입한다.\n\\(n=3\\)이라하면, where은 ",
  "wordCount" : "350",
  "inLanguage": "en",
  "datePublished": "2024-01-12T15:48:20+09:00",
  "dateModified": "2024-01-12T15:48:20+09:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://ownogatari.xyz/posts/fasttext/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "미래사회와 창의혁신인재",
    "logo": {
      "@type": "ImageObject",
      "url": "https://ownogatari.xyz/images/favicon/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://ownogatari.xyz/" accesskey="h" title="미래사회와 창의혁신인재 (Alt + H)">미래사회와 창의혁신인재</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://ownogatari.xyz/categories/" title="categories">
                    <span>categories</span>
                </a>
            </li>
            <li>
                <a href="https://ownogatari.xyz/tags/" title="tags">
                    <span>tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://ownogatari.xyz/">Home</a>&nbsp;»&nbsp;<a href="https://ownogatari.xyz/posts/">Posts</a></div>
    <h1 class="post-title">
      FastText
    </h1>
    <div class="post-meta"><span title='2024-01-12 15:48:20 +0900 +0900'>January 12, 2024</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;350 words

</div>
  </header> 
  <div class="post-content"><h1 id="1-overview">1. overview<a hidden class="anchor" aria-hidden="true" href="#1-overview">#</a></h1>
<h2 id="11-objective">1.1 objective<a hidden class="anchor" aria-hidden="true" href="#11-objective">#</a></h2>
<p>단어를 형태소의 측면에서 표현해보자.</p>
<h2 id="12-background">1.2 background<a hidden class="anchor" aria-hidden="true" href="#12-background">#</a></h2>
<h3 id="121-형태소적-접근">1.2.1 형태소적 접근<a hidden class="anchor" aria-hidden="true" href="#121-형태소적-접근">#</a></h3>
<ul>
<li>기존의 단어 표현은 하나의 단어당 하나의 벡터로 이루어졌다.</li>
<li>하나의 단어를 여러 형태소의 벡터로 표현해보자.
<ul>
<li><code>먹음</code>에 대해서 <code>먹기</code>, <code>먹이</code>, <code>먹는</code>, <code>먹다</code>, <code>먹었음</code>, <code>먹었다</code> 등 여러 형태가 나타날 수 있다.</li>
<li>그러나, 훈련 데이터에는 모든 형태가 등장하지 않는다.</li>
<li>그렇게 되면, 등장하지 않는 단어에 대해서representation이 떨어질 수 있다.</li>
<li>만약 형태소로 접근한다면, <code>-기</code>, <code>-이</code>, <code>-는</code>의 형태는 다른 단어들에서 볼 수 있다.</li>
<li>즉, <code>먹었음</code>이 훈련데이터에 없다해도, <code>먹-</code>, <code>-었-</code>, <code>-음</code>의 합으로 표현할 수 있다.</li>
</ul>
</li>
</ul>
<h3 id="122-skip-gram">1.2.2 Skip Gram<a hidden class="anchor" aria-hidden="true" href="#122-skip-gram">#</a></h3>
<p>skipgram: 하나의 단어가 주어지면, 주변의 단어를 맞추는 것.</p>
<p>데이터가 주어졌을 때, 아래 식을 최대화하는 것이 목적.</p>
<p>$$\sum_{t=1}^{T}\sum_{c\in{\cal C}<em>{t}}\log p(w</em>{c} \ | \ w_{t})$$</p>
<p>확률 \(p\)는 softmax로 표현 될 수 있다.</p>
<p>$$p(w_{c}\mid w_{t})=\frac{e^{s(w_{t},w_{c})}}{\sum_{j=1}^{W}e^{s(w_{t},j)}}$$</p>
<p>\(s(w_t,w_c)\)는 \(w_t\)와 \(w_c\)의 유사도를 구하는 함수이다.</p>
<p>$$s(w_{t},{w}<em>{c}),=,{\mathbf{u}}</em>{w_{t}}^{\mathsf{T}}{\mathbf{v}}<em>{w</em>{c}}$$</p>
<h1 id="2-main">2. main<a hidden class="anchor" aria-hidden="true" href="#2-main">#</a></h1>
<p>general model + subword model</p>
<h2 id="21-architecture">2.1 architecture<a hidden class="anchor" aria-hidden="true" href="#21-architecture">#</a></h2>
<h3 id="211-general-model">2.1.1 General model<a hidden class="anchor" aria-hidden="true" href="#211-general-model">#</a></h3>
<p>변형 skipgram을 사용한다.</p>
<h4 id="binary-log-loss-with-negative-sampling">Binary log loss with negative sampling<a hidden class="anchor" aria-hidden="true" href="#binary-log-loss-with-negative-sampling">#</a></h4>
<p>기존의 skipgram은 Softmax log loss를 사용한다. 이렇게 되면, \(w_t\)에 대해서 하나의 \(w_c\)를 예측하는 것으로 학습이 된다.</p>
<p>여러 개의 \(w_c\)를 예측하기 위해서는 \(c\)마다 binary class 예측을 해야한다. 따라서, loss를 binary loss로 바꿔준다.</p>
<p>$$\log\left(1+e^{-s(w_{t},,w_{c})}\right)+\sum_{n\in\mathcal{N}<em>{t.c}}\log\left(1+e^{s(w</em>{t},,n)}\right)$$</p>
<ul>
<li>첫번째 term: \(w_t\)와 \(w_c\)의 유사도를 비슷하게 만들도록 학습</li>
<li>두번째 term: \(w_t\)와 \(n\)의 유사도를 다르게 만들도록 학습</li>
</ul>
<h3 id="212-subword-model">2.1.2 Subword model<a hidden class="anchor" aria-hidden="true" href="#212-subword-model">#</a></h3>
<p>우선 where이라는 단어가 있을 때, 이를 \(&lt; where &gt;\)로 바꿔준다. 이 때, <code>&lt;</code>와 <code>&gt;</code>는 경계를 나타낸다.
\(\leftarrow\) 형태소는 하나의 단어를 기준으로 하기 때문에 필요하다.</p>
<p>그 후 character \(n\)-gram을 도입한다.</p>
<p>\(n=3\)이라하면, <code>where</code>은 <code>&lt;wh</code>, <code>whe</code>,<code>her</code>, <code>ere</code>, <code>re&gt;</code>로 나누어진다. 각각을 \(g_1,g_2,g_3,g_4,g_5\)라고 하자.</p>
<p>또, <code>&lt;where&gt;</code> 역시 special sequence로 \(g_6\)라 하자.</p>
<p>이제 주변 단어에 대해서 where 한 단어와 비교하는 것이 아니라, \(g_{1\sim}g_6\) 와 비교하는 과정으로 바꿀 것이다.</p>
<p>$$s(w,c)=\sum_{g\in{\mathcal G}<em>{w}}\mathbf{z}</em>{g}^{\top}\mathbf{v}_{c}.$$</p>
<p>이렇게 되면 장점은 나중에 못본 단어<code>&lt;when&gt;</code>가 있다고 할 때, <code>&lt;where&gt;</code>에서의 <code>&lt;wh</code>,<code>whe</code> 를 재사용할 수 있게 된다. \(\Rightarrow\) out of vocabulary 문제 해결 가능.</p>
<h1 id="3-experiments">3. experiments<a hidden class="anchor" aria-hidden="true" href="#3-experiments">#</a></h1>
<p>우리의 모델 sisg는 human-judge와 유사도가 다른 모델들보다 크다.
<img loading="lazy" src="https://github.com/ownvoy/ownogatari/assets/96481582/d6f70da5-ca71-4156-80f4-eb934ea960df" alt="image"  />
</p>
<p>word anlalogy task에서도 syntatic에 대한 측면에서 우수한 점수를 보인다. symentic에 대해 점수가 낮은 것은 아무래도 의미 단위 없이 나누었기 때문으로 보임.</p>
<p><strong>word analogy task</strong>: A is to B as C is to D. ex) (왕,왕비), (할아버지,?)</p>
<p><img loading="lazy" src="https://github.com/ownvoy/ownogatari/assets/96481582/152b129d-bc89-41a5-b03d-b409dcc9df59" alt="image"  />
</p>
<p>\(n\)을 키우면 symentic에 대한 성능이 조금은 나아짐. (세로축: 단어의 char개수, 가로축: n-gram)
<img loading="lazy" src="https://github.com/ownvoy/ownogatari/assets/96481582/38e82290-195c-4f25-86bd-18dd318119ea" alt="image"  />
</p>
<p>적은 양의 데이터에서도 우수한 성능을 보인다. 이는 하나의 단어를 쪼개었기때문으로 보임.
<img loading="lazy" src="https://github.com/ownvoy/ownogatari/assets/96481582/e4dfa006-1800-4f8e-afe3-aa1c8fcc67e6" alt="image"  />
</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
<nav class="paginav">
  <a class="next" href="https://ownogatari.xyz/posts/retinanet/">
    <span class="title">Next »</span>
    <br>
    <span>RetinaNet</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    <link rel="stylesheet" href="./zotero.css">
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<footer class="footer">
    
</footer>
</div>

</body>


</html></body>

</html>
