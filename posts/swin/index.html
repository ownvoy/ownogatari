<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Swin Transformer | 미래사회와 창의혁신인재</title>
<meta name="keywords" content="">
<meta name="description" content="1. overview 1.1 objective Transformer에 inductive bias를 주입하자. Transformer의 계산 효율성을 높여보자. 1.2 background 1.2.1 ViT 기존 ViT의 문제점으로 2가지가 있다.
Fixed scale 기본적으로 16크기의 Patch를 쓴다. CV같은 다양한 scale로 보는 것이 중요하다.(ex: FPN) complexity Image Segmentation 이나, Depth Estimation 같은 경우, 높은 해상도를 필요로 한다. ViT의 attention 경우 \(O(N^2)\)의 시간복잡도를 가진다. Swin Transformer의 경우 Patch Merging을 통해 (1)의 문제를 Window Attention을 통해 (2)의 문제를 해결한다.
2. main 2.1 architecture 2.">
<meta name="author" content="Won Jun Oh">
<link rel="canonical" href="https://ownogatari.xyz/posts/swin/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.5cfc680b1eeaeef9efbced92d46c2a9e876b72ee14fba85846afc4cff9e6e6f8.css" integrity="sha256-XPxoCx7q7vnvvO2S1Gwqnodrcu4U&#43;6hYRq/Ez/nm5vg=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://ownogatari.xyz/images/favicon/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://ownogatari.xyz/images/favicon/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://ownogatari.xyz/images/favicon/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://ownogatari.xyz/images/favicon/apple-touch-icon.png">
<link rel="mask-icon" href="https://ownogatari.xyz/images/favicon/apple-touch-icon.png">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="Swin Transformer" />
<meta property="og:description" content="1. overview 1.1 objective Transformer에 inductive bias를 주입하자. Transformer의 계산 효율성을 높여보자. 1.2 background 1.2.1 ViT 기존 ViT의 문제점으로 2가지가 있다.
Fixed scale 기본적으로 16크기의 Patch를 쓴다. CV같은 다양한 scale로 보는 것이 중요하다.(ex: FPN) complexity Image Segmentation 이나, Depth Estimation 같은 경우, 높은 해상도를 필요로 한다. ViT의 attention 경우 \(O(N^2)\)의 시간복잡도를 가진다. Swin Transformer의 경우 Patch Merging을 통해 (1)의 문제를 Window Attention을 통해 (2)의 문제를 해결한다.
2. main 2.1 architecture 2." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://ownogatari.xyz/posts/swin/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-29T23:20:05+09:00" />
<meta property="article:modified_time" content="2024-01-29T23:20:05+09:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Swin Transformer"/>
<meta name="twitter:description" content="1. overview 1.1 objective Transformer에 inductive bias를 주입하자. Transformer의 계산 효율성을 높여보자. 1.2 background 1.2.1 ViT 기존 ViT의 문제점으로 2가지가 있다.
Fixed scale 기본적으로 16크기의 Patch를 쓴다. CV같은 다양한 scale로 보는 것이 중요하다.(ex: FPN) complexity Image Segmentation 이나, Depth Estimation 같은 경우, 높은 해상도를 필요로 한다. ViT의 attention 경우 \(O(N^2)\)의 시간복잡도를 가진다. Swin Transformer의 경우 Patch Merging을 통해 (1)의 문제를 Window Attention을 통해 (2)의 문제를 해결한다.
2. main 2.1 architecture 2."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://ownogatari.xyz/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Swin Transformer",
      "item": "https://ownogatari.xyz/posts/swin/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Swin Transformer",
  "name": "Swin Transformer",
  "description": "1. overview 1.1 objective Transformer에 inductive bias를 주입하자. Transformer의 계산 효율성을 높여보자. 1.2 background 1.2.1 ViT 기존 ViT의 문제점으로 2가지가 있다.\nFixed scale 기본적으로 16크기의 Patch를 쓴다. CV같은 다양한 scale로 보는 것이 중요하다.(ex: FPN) complexity Image Segmentation 이나, Depth Estimation 같은 경우, 높은 해상도를 필요로 한다. ViT의 attention 경우 \\(O(N^2)\\)의 시간복잡도를 가진다. Swin Transformer의 경우 Patch Merging을 통해 (1)의 문제를 Window Attention을 통해 (2)의 문제를 해결한다.\n2. main 2.1 architecture 2.",
  "keywords": [
    
  ],
  "articleBody": "1. overview 1.1 objective Transformer에 inductive bias를 주입하자. Transformer의 계산 효율성을 높여보자. 1.2 background 1.2.1 ViT 기존 ViT의 문제점으로 2가지가 있다.\nFixed scale 기본적으로 16크기의 Patch를 쓴다. CV같은 다양한 scale로 보는 것이 중요하다.(ex: FPN) complexity Image Segmentation 이나, Depth Estimation 같은 경우, 높은 해상도를 필요로 한다. ViT의 attention 경우 \\(O(N^2)\\)의 시간복잡도를 가진다. Swin Transformer의 경우 Patch Merging을 통해 (1)의 문제를 Window Attention을 통해 (2)의 문제를 해결한다.\n2. main 2.1 architecture 2.1.1 Window Attention 그림과 같이 각각의 색깔 cell들을 window라고 한다. 그림에서는 Window 하나 당 2 * 2의 patch를 가지지만, 보통 7 * 7의 patch를 가진다. 가장 큰 특징으로는 window 안에서만 attention이 일어난다. \\(\\Rightarrow\\) 기존의 attention은 patch마다 attention을 수행했기에 \\(O((HW)^2)\\)의 시간복잡도를 가지는데, Window attention의 경우,\\(O(M^2)\\)로 시간 복잡도가 줄어든다. 2.1.2 Patch Merging Window attention을 하게 되면, 국소적으로만 attention을 하게 되는 문제점이 있다. 이를 해결하고자, patch 사이즈를 (4-\u003e8-\u003e16)키우게 된다. 이는 scale에서도 상당한 이점이 있다. 단순히 patch 사이즈를 키우는게 아니라, 차원을 더 깊게 만들어준다.(Hierachical한 구조) 2.1.3 Patch Merging + Window Attention 전체적인 구조는 Patch Merging과 Window attention이 반복되는 구조이다. 여기에 Shifted windows라는 것 추가된다.\n2.1.4 Shifted Windows 그러나, 이러한 형태의 window attention은 문제가 있다.\n위와 같이, 각각의 patch들은 가까이 있음에도 attention을 안하게 된다.(circle)\n이를 해결하기 위해서는 shifted window를 도입하여, 저것들도 attention을 해주면 된다. 이것이 shifted window인 이유는, 기존의 window를 window size/2 만큼 오른쪽으로 아래쪽으로 움직이기 때문이다.\n2.1.5 Batch cyclic-shift Shifted Window에 문제가 있다.\n각각의 window의 크기가 다르다. window의 수가 늘어난다. \\(\\Rightarrow\\) attention 횟수가 늘어난다. Cyclic shift를 써서 이 문제를 해결한다. 왼쪽과 위쪽의 윈도우들을 오른쪽으로 아래로 민 것이다. 이렇게 했을 때 위의 문제를 해결할 수 있다.\n2 * 2로 window size를 다시 맞춰준다. 원래의 인접하지 않는 윈도우는 masking을 해줘서 attention 계산을 해준다. (attention 횟수 유지) 3. experiments 3.1 model variants Swin-T: C=96, layer numbers={2,2,6,2} Swin-S: C=96, layer numbers={2,2,18,2} Swin-B: C=128, layer numbers={2,2,18,2} Swin-L: C=192, layer numbers={2,2,18,2} 각 layer가 짝수 인것은 window msa랑 shifted window msa가 쌍으로 이루어지기 때문이다.\n3.2 experiments classification에서 정확도랑 속도가 높은 것을 확인할 수 있다.\nobject detection task에서 swin transformer가 backbone으로 쓰였을 때.\nshifted windows를 썼을 때의 정확도가 높은 것을 볼 수 있다.\ncyclic shift를 썼을 때 속도가 빠른 것을 볼 수 있다.\n",
  "wordCount" : "341",
  "inLanguage": "en",
  "datePublished": "2024-01-29T23:20:05+09:00",
  "dateModified": "2024-01-29T23:20:05+09:00",
  "author":[{
    "@type": "Person",
    "name": "Won Jun Oh"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://ownogatari.xyz/posts/swin/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "미래사회와 창의혁신인재",
    "logo": {
      "@type": "ImageObject",
      "url": "https://ownogatari.xyz/images/favicon/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://ownogatari.xyz/" accesskey="h" title="미래사회와 창의혁신인재 (Alt + H)">미래사회와 창의혁신인재</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://ownogatari.xyz/categories/" title="categories">
                    <span>categories</span>
                </a>
            </li>
            <li>
                <a href="https://ownogatari.xyz/tags/" title="tags">
                    <span>tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://ownogatari.xyz/">Home</a>&nbsp;»&nbsp;<a href="https://ownogatari.xyz/posts/">Posts</a></div>
    <h1 class="post-title">
      Swin Transformer
    </h1>
    <div class="post-meta"><span title='2024-01-29 23:20:05 +0900 +0900'>January 29, 2024</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;341 words&nbsp;·&nbsp;Won Jun Oh

</div>
  </header> 
  <div class="post-content"><h1 id="1-overview">1. overview<a hidden class="anchor" aria-hidden="true" href="#1-overview">#</a></h1>
<h2 id="11-objective">1.1 objective<a hidden class="anchor" aria-hidden="true" href="#11-objective">#</a></h2>
<ul>
<li>Transformer에 inductive bias를 주입하자.</li>
<li>Transformer의 계산 효율성을 높여보자.</li>
</ul>
<h2 id="12-background">1.2 background<a hidden class="anchor" aria-hidden="true" href="#12-background">#</a></h2>
<h3 id="121-vit">1.2.1 ViT<a hidden class="anchor" aria-hidden="true" href="#121-vit">#</a></h3>
<p>기존 ViT의 문제점으로 2가지가 있다.</p>
<ol>
<li>Fixed scale
<ul>
<li>기본적으로 16크기의 Patch를 쓴다.</li>
<li>CV같은 다양한 scale로 보는 것이 중요하다.(ex: FPN)</li>
</ul>
</li>
<li>complexity
<ul>
<li>Image Segmentation 이나, Depth Estimation 같은 경우, 높은 해상도를 필요로 한다.</li>
<li>ViT의 attention 경우 \(O(N^2)\)의 시간복잡도를 가진다.</li>
</ul>
</li>
</ol>
<p>Swin Transformer의 경우 Patch Merging을 통해 (1)의 문제를 Window Attention을 통해 (2)의 문제를 해결한다.</p>
<h1 id="2-main">2. main<a hidden class="anchor" aria-hidden="true" href="#2-main">#</a></h1>
<h2 id="21-architecture">2.1 architecture<a hidden class="anchor" aria-hidden="true" href="#21-architecture">#</a></h2>
<h3 id="211-window-attention">2.1.1 Window Attention<a hidden class="anchor" aria-hidden="true" href="#211-window-attention">#</a></h3>
<p><img loading="lazy" src="https://github.com/ownvoy/ownogatari/assets/96481582/4c744e0b-1cec-4736-9527-6a9ec644f8a4" alt="image"  />
</p>
<ul>
<li>그림과 같이 각각의 색깔 cell들을 window라고 한다.</li>
<li>그림에서는 Window 하나 당 2 * 2의 patch를 가지지만, 보통 7 * 7의 patch를 가진다.</li>
<li><strong>가장 큰 특징으로는 window 안에서만 attention이 일어난다.</strong> \(\Rightarrow\) 기존의 attention은 patch마다 attention을 수행했기에 \(O((HW)^2)\)의 시간복잡도를 가지는데, Window attention의 경우,\(O(M^2)\)로 시간 복잡도가 줄어든다.</li>
</ul>
<h3 id="212-patch-merging">2.1.2 Patch Merging<a hidden class="anchor" aria-hidden="true" href="#212-patch-merging">#</a></h3>
<ul>
<li>Window attention을 하게 되면, 국소적으로만 attention을 하게 되는 문제점이 있다.</li>
<li>이를 해결하고자, patch 사이즈를 (4-&gt;8-&gt;16)키우게 된다.</li>
<li>이는 scale에서도 상당한 이점이 있다.</li>
<li>단순히 patch 사이즈를 키우는게 아니라, 차원을 더 깊게 만들어준다.(Hierachical한 구조)
<img loading="lazy" src="https://github.com/ownvoy/ownogatari/assets/96481582/f8e801c6-f55a-47c1-9465-5221af0a0f67" alt="image"  />
</li>
</ul>
<h3 id="213-patch-merging--window-attention">2.1.3 Patch Merging + Window Attention<a hidden class="anchor" aria-hidden="true" href="#213-patch-merging--window-attention">#</a></h3>
<p><img loading="lazy" src="https://github.com/ownvoy/ownogatari/assets/96481582/7d9bb5a6-25b0-4ac4-bfbd-9c3ef7f662de" alt="image"  />

전체적인 구조는 Patch Merging과 Window attention이 반복되는 구조이다. 여기에 Shifted windows라는 것 추가된다.</p>
<h3 id="214-shifted-windows">2.1.4 Shifted Windows<a hidden class="anchor" aria-hidden="true" href="#214-shifted-windows">#</a></h3>
<p><img loading="lazy" src="https://github.com/ownvoy/ownogatari/assets/96481582/f0835c9e-2331-436f-a6dd-ea785fe169e2" alt="image"  />
</p>
<p>그러나, 이러한 형태의 window attention은 문제가 있다.</p>
<p><img loading="lazy" src="https://github.com/ownvoy/ownogatari/assets/96481582/36042a13-29f9-455b-b042-4b3216d83980" alt="image"  />
</p>
<p>위와 같이, 각각의 patch들은 가까이 있음에도 attention을 안하게 된다.(circle)</p>
<p>이를 해결하기 위해서는 shifted window를 도입하여, 저것들도 attention을 해주면 된다.
<img loading="lazy" src="https://github.com/ownvoy/ownogatari/assets/96481582/dc2c4a2a-97f7-4d86-98b0-dc18dc2f44b8" alt="image"  />
</p>
<p>이것이 shifted window인 이유는, 기존의 window를 window size/2 만큼 오른쪽으로 아래쪽으로 움직이기 때문이다.</p>
<p><img loading="lazy" src="https://github.com/ownvoy/ownogatari/assets/96481582/1f4829ed-7791-454e-aab2-6285add8162c" alt="image"  />
</p>
<h3 id="215-batch-cyclic-shift">2.1.5 Batch cyclic-shift<a hidden class="anchor" aria-hidden="true" href="#215-batch-cyclic-shift">#</a></h3>
<p><img loading="lazy" src="https://github.com/ownvoy/ownogatari/assets/96481582/dc2c4a2a-97f7-4d86-98b0-dc18dc2f44b8" alt="image"  />

Shifted Window에 문제가 있다.</p>
<ol>
<li>각각의 window의 크기가 다르다.</li>
<li>window의 수가 늘어난다. \(\Rightarrow\) attention 횟수가 늘어난다.</li>
</ol>
<p>Cyclic shift를 써서 이 문제를 해결한다.
<img loading="lazy" src="https://github.com/ownvoy/ownogatari/assets/96481582/cd4dda32-77f1-484d-aaee-3740711bc5e8" alt="image"  />

왼쪽과 위쪽의 윈도우들을 오른쪽으로 아래로 민 것이다.
이렇게 했을 때 위의 문제를 해결할 수 있다.</p>
<ol>
<li>2 * 2로 window size를 다시 맞춰준다.</li>
<li>원래의 인접하지 않는 윈도우는 masking을 해줘서 attention 계산을 해준다. (attention 횟수 유지)</li>
</ol>
<h1 id="3-experiments">3. experiments<a hidden class="anchor" aria-hidden="true" href="#3-experiments">#</a></h1>
<h2 id="31-model-variants">3.1 model variants<a hidden class="anchor" aria-hidden="true" href="#31-model-variants">#</a></h2>
<ul>
<li>Swin-T: C=96, layer numbers={2,2,6,2}</li>
<li>Swin-S: C=96, layer numbers={2,2,18,2}</li>
<li>Swin-B: C=128, layer numbers={2,2,18,2}</li>
<li>Swin-L: C=192, layer numbers={2,2,18,2}</li>
</ul>
<p>각 layer가 짝수 인것은 window msa랑 shifted window msa가 쌍으로 이루어지기 때문이다.</p>
<h2 id="32-experiments">3.2 experiments<a hidden class="anchor" aria-hidden="true" href="#32-experiments">#</a></h2>
<p><img loading="lazy" src="https://github.com/ownvoy/ownogatari/assets/96481582/3ce56043-c9ab-48de-8d46-dc8dc11224f7" alt="image"  />

classification에서 정확도랑 속도가 높은 것을 확인할 수 있다.</p>
<p><img loading="lazy" src="https://github.com/ownvoy/ownogatari/assets/96481582/2f4857d6-62ce-4cae-8fee-6a59795088c9" alt="image"  />

object detection task에서 swin transformer가 backbone으로 쓰였을 때.</p>
<p><img loading="lazy" src="https://github.com/ownvoy/ownogatari/assets/96481582/37533dab-7a67-4039-a4de-f1854521a9fc" alt="image"  />

shifted windows를 썼을 때의 정확도가 높은 것을 볼 수 있다.</p>
<p><img loading="lazy" src="https://github.com/ownvoy/ownogatari/assets/96481582/7f00a676-32f1-4edb-909a-3e0066fb1136" alt="image"  />

cyclic shift를 썼을 때 속도가 빠른 것을 볼 수 있다.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
<nav class="paginav">
  <a class="next" href="https://ownogatari.xyz/posts/detr/">
    <span class="title">Next »</span>
    <br>
    <span>DETR</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    <footer class="footer">
    
</footer>
</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css"
    integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous"
    referrerpolicy="no-referrer">

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js"
    integrity="sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY" crossorigin="anonymous"
    referrerpolicy="no-referrer" type="text/javascript"></script>

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js"
    integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous"
    referrerpolicy="no-referrer" type="text/javascript"></script>

<script type="text/javascript">
    document.addEventListener("DOMContentLoaded", function () {
        renderMathInElement(document.body, {
            delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "//[", right: "//]", display: true },
                { left: "$", right: "$", display: false },
                { left: "\\(", right: "\\)", display: false },
            ],
        });
    });
</script>
</body>

</html></body>

</html>
