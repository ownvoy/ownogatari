<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>DETR | 미래사회와 창의혁신인재</title>
<meta name="keywords" content="CV">
<meta name="description" content="1. overview 1.1 objective detection에서 transformer를 사용해보자. detection에서 end to end 학습을 해보자. NMS, anchor setting의 부차적인 과정들이 학습의 결과에 많은 영향을 미친다. Transformer를 통해 위 두 개의 과정을 없앨 수 있게 된다.
2. main 2.1 Transformer DETR은 기본적으로 Transforemer 구조를 따른다. DeTR에서 Encoder와 Decoder가 무슨 역할을 하는지 보도록 한다.
2.1.1 Encoder cnn을 통과한 feature-map이 쪼개져서 input으로 들어온다. (ViT 스타일)
그 후, attention 계산을 통해 그림 전체에 대한 정보를 본다.">
<meta name="author" content="Won Jun Oh">
<link rel="canonical" href="https://ownogatari.xyz/posts/detr/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.5cfc680b1eeaeef9efbced92d46c2a9e876b72ee14fba85846afc4cff9e6e6f8.css" integrity="sha256-XPxoCx7q7vnvvO2S1Gwqnodrcu4U&#43;6hYRq/Ez/nm5vg=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://ownogatari.xyz/images/favicon/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://ownogatari.xyz/images/favicon/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://ownogatari.xyz/images/favicon/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://ownogatari.xyz/images/favicon/apple-touch-icon.png">
<link rel="mask-icon" href="https://ownogatari.xyz/images/favicon/apple-touch-icon.png">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="DETR" />
<meta property="og:description" content="1. overview 1.1 objective detection에서 transformer를 사용해보자. detection에서 end to end 학습을 해보자. NMS, anchor setting의 부차적인 과정들이 학습의 결과에 많은 영향을 미친다. Transformer를 통해 위 두 개의 과정을 없앨 수 있게 된다.
2. main 2.1 Transformer DETR은 기본적으로 Transforemer 구조를 따른다. DeTR에서 Encoder와 Decoder가 무슨 역할을 하는지 보도록 한다.
2.1.1 Encoder cnn을 통과한 feature-map이 쪼개져서 input으로 들어온다. (ViT 스타일)
그 후, attention 계산을 통해 그림 전체에 대한 정보를 본다." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://ownogatari.xyz/posts/detr/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-19T13:28:40+09:00" />
<meta property="article:modified_time" content="2024-01-19T13:28:40+09:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="DETR"/>
<meta name="twitter:description" content="1. overview 1.1 objective detection에서 transformer를 사용해보자. detection에서 end to end 학습을 해보자. NMS, anchor setting의 부차적인 과정들이 학습의 결과에 많은 영향을 미친다. Transformer를 통해 위 두 개의 과정을 없앨 수 있게 된다.
2. main 2.1 Transformer DETR은 기본적으로 Transforemer 구조를 따른다. DeTR에서 Encoder와 Decoder가 무슨 역할을 하는지 보도록 한다.
2.1.1 Encoder cnn을 통과한 feature-map이 쪼개져서 input으로 들어온다. (ViT 스타일)
그 후, attention 계산을 통해 그림 전체에 대한 정보를 본다."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://ownogatari.xyz/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "DETR",
      "item": "https://ownogatari.xyz/posts/detr/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "DETR",
  "name": "DETR",
  "description": "1. overview 1.1 objective detection에서 transformer를 사용해보자. detection에서 end to end 학습을 해보자. NMS, anchor setting의 부차적인 과정들이 학습의 결과에 많은 영향을 미친다. Transformer를 통해 위 두 개의 과정을 없앨 수 있게 된다.\n2. main 2.1 Transformer DETR은 기본적으로 Transforemer 구조를 따른다. DeTR에서 Encoder와 Decoder가 무슨 역할을 하는지 보도록 한다.\n2.1.1 Encoder cnn을 통과한 feature-map이 쪼개져서 input으로 들어온다. (ViT 스타일)\n그 후, attention 계산을 통해 그림 전체에 대한 정보를 본다.",
  "keywords": [
    "CV"
  ],
  "articleBody": "1. overview 1.1 objective detection에서 transformer를 사용해보자. detection에서 end to end 학습을 해보자. NMS, anchor setting의 부차적인 과정들이 학습의 결과에 많은 영향을 미친다. Transformer를 통해 위 두 개의 과정을 없앨 수 있게 된다.\n2. main 2.1 Transformer DETR은 기본적으로 Transforemer 구조를 따른다. DeTR에서 Encoder와 Decoder가 무슨 역할을 하는지 보도록 한다.\n2.1.1 Encoder cnn을 통과한 feature-map이 쪼개져서 input으로 들어온다. (ViT 스타일)\n그 후, attention 계산을 통해 그림 전체에 대한 정보를 본다.\nEncoder에서 self attention이다. 물체들을 구별하는 것을 볼 수 있다. 2.1.2 Decoder decoder의 query는 output으로 box와 class를 내놓는다.(decoder의 query가 일반 Transformer에서 EOS1, EOS2, …,EOSN과 같은 느낌을 받음. output이 sequence 형태가 아니니까 inference할 때도, parallel하게 할 수 있음. DETR은 auto-regressive하지 않음. object query는 각각의 고유한 것을 예측해야하기 때문에 learnable positional embedding임. encoder의 사진 전체에 대한 정보를 참고하여, output을 뽑는다. output의 attention은 사물의 가장자리를 보는 것을 알 수 있다. img에서 prediction이 나옴으로, anchor setting에서 자유롭다. anchor 자체가 없다. 2.2 Set prediction decoder의 쿼리가 들어가면 set으로 (box,class)가 나온다.\ndecoder의 쿼리 수 \\(N\\)은 무조건 사진의 object 수보다 크게 설정한다. object가 없을 경우 \\(\\emptyset\\)(no object)으로 매칭 2.2.1 Set prediction의 이점 일대일 매칭이어서 NMS를 피할 수 있다. 2.2.2 Set prediction loss \\(y\\)랑 \\(\\hat{y}\\) 를 가능한 1-1 매칭을 해보고, loss가 가장 적은 정책을 \\(\\hat{\\sigma}\\)라고 한다. 이는 Hungarian algorithm를 통해 사용.\n\\[\\hat{\\sigma}={\\underset{\\sigma\\in S_{N}}{\\arg\\min}}\\sum_{i}^{N}L_{match}(y_{i},\\hat{y}_{\\sigma(i)})\\]\n가장 최적의 \\(\\hat{\\sigma}\\)를 통해 답과의 loss를 구한다.\n//[L_{Hungarian}(y,\\hat{y})=\\sum_{i=1}^N\\left[-\\log\\hat{p}{\\hat{\\sigma}(i)}(c_i)+1{c_i\\neq\\emptyset}L_{box}(b_{i},\\hat{b}_{\\hat{\\sigma}}(i))\\right]//]\nclass가 맞으면, Loss가 작아지는 식의 Cross Entropy Loss + box의 차이가 작으면, loss가 작아지는 식이다.\nbounding box loss\n//[\\lambda_{iou}L_{iou}(b_i,\\hat{b}{\\sigma(i)})+ \\lambda{L1}\\mid\\mid b_{i}-\\hat{b}_{\\sigma(i)}\\mid\\mid_1//]\n그냥 L1 loss만으로는 scale에 대해 영향을 많이 받으므로 generalized iou 도입.\n3. experiments DETR는 비슷 한수의 param과 FLOPS를 가진 Faster RCNN보다 성능이 좋은 것을 볼 수 있다. 다만, 작은 물체의 경우 Faster RCNN의 결과가 좋다.\n",
  "wordCount" : "268",
  "inLanguage": "en",
  "datePublished": "2024-01-19T13:28:40+09:00",
  "dateModified": "2024-01-19T13:28:40+09:00",
  "author":[{
    "@type": "Person",
    "name": "Won Jun Oh"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://ownogatari.xyz/posts/detr/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "미래사회와 창의혁신인재",
    "logo": {
      "@type": "ImageObject",
      "url": "https://ownogatari.xyz/images/favicon/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://ownogatari.xyz/" accesskey="h" title="미래사회와 창의혁신인재 (Alt + H)">미래사회와 창의혁신인재</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://ownogatari.xyz/categories/" title="categories">
                    <span>categories</span>
                </a>
            </li>
            <li>
                <a href="https://ownogatari.xyz/tags/" title="tags">
                    <span>tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://ownogatari.xyz/">Home</a>&nbsp;»&nbsp;<a href="https://ownogatari.xyz/posts/">Posts</a></div>
    <h1 class="post-title">
      DETR
    </h1>
    <div class="post-meta"><span title='2024-01-19 13:28:40 +0900 +0900'>January 19, 2024</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;268 words&nbsp;·&nbsp;Won Jun Oh

</div>
  </header> 
  <div class="post-content"><h1 id="1-overview">1. overview<a hidden class="anchor" aria-hidden="true" href="#1-overview">#</a></h1>
<h2 id="11-objective">1.1 objective<a hidden class="anchor" aria-hidden="true" href="#11-objective">#</a></h2>
<ul>
<li>detection에서 transformer를 사용해보자.</li>
<li>detection에서 end to end 학습을 해보자.</li>
</ul>
<p>NMS, anchor setting의 부차적인 과정들이 학습의 결과에 많은 영향을 미친다. Transformer를 통해 위 두 개의 과정을 없앨 수 있게 된다.</p>
<h1 id="2-main">2. main<a hidden class="anchor" aria-hidden="true" href="#2-main">#</a></h1>
<h2 id="21-transformer">2.1 Transformer<a hidden class="anchor" aria-hidden="true" href="#21-transformer">#</a></h2>
<p><img loading="lazy" src="https://github.com/ownvoy/ownogatari/assets/96481582/3c6be95f-25a9-466f-a7cd-32a6946f8cef" alt="image"  />

DETR은 기본적으로 Transforemer 구조를 따른다. DeTR에서 Encoder와 Decoder가 무슨 역할을 하는지 보도록 한다.</p>
<h3 id="211-encoder">2.1.1 Encoder<a hidden class="anchor" aria-hidden="true" href="#211-encoder">#</a></h3>
<ul>
<li>
<p>cnn을 통과한 feature-map이 쪼개져서 input으로 들어온다. (ViT 스타일)</p>
</li>
<li>
<p>그 후, attention 계산을 통해 그림 전체에 대한 정보를 본다.</p>
</li>
<li>
<p>Encoder에서 self attention이다. 물체들을 구별하는 것을 볼 수 있다.
<img loading="lazy" src="https://github.com/ownvoy/ownogatari/assets/96481582/5c4633b1-d90e-4385-862c-0e8ba375e9c4" alt="image"  />
</p>
</li>
</ul>
<h3 id="212-decoder">2.1.2 Decoder<a hidden class="anchor" aria-hidden="true" href="#212-decoder">#</a></h3>
<ul>
<li>decoder의 query는 output으로 box와 class를 내놓는다.(decoder의 query가 일반 Transformer에서 EOS1, EOS2, &hellip;,EOSN과 같은 느낌을 받음.</li>
<li>output이 sequence 형태가 아니니까 inference할 때도, parallel하게 할 수 있음. DETR은 auto-regressive하지 않음.</li>
<li>object query는 각각의 고유한 것을 예측해야하기 때문에 learnable positional embedding임.
<img loading="lazy" src="https://github.com/ownvoy/ownogatari/assets/96481582/7514a9b5-bd64-4991-b90f-b98ae5b31bca" alt="image"  />
</li>
<li>encoder의 사진 전체에 대한 정보를 참고하여, output을 뽑는다. output의 attention은 사물의 가장자리를 보는 것을 알 수 있다.</li>
<li><strong>img에서 prediction이 나옴으로, anchor setting에서 자유롭다. anchor 자체가 없다.</strong></li>
</ul>
<h2 id="22-set-prediction">2.2 Set prediction<a hidden class="anchor" aria-hidden="true" href="#22-set-prediction">#</a></h2>
<p>decoder의 쿼리가 들어가면 set으로 (box,class)가 나온다.</p>
<p>decoder의 쿼리 수 \(N\)은 무조건 사진의 object 수보다 크게 설정한다. object가 없을 경우 \(\emptyset\)(no object)으로 매칭
<img loading="lazy" src="https://github.com/ownvoy/ownogatari/assets/96481582/899559be-99ec-409d-a73a-0dce868eae8d" alt="image"  />
</p>
<h3 id="221-set-prediction의-이점">2.2.1 Set prediction의 이점<a hidden class="anchor" aria-hidden="true" href="#221-set-prediction의-이점">#</a></h3>
<ul>
<li><strong>일대일 매칭이어서 NMS를 피할 수 있다.</strong></li>
</ul>
<h3 id="222-set-prediction-loss">2.2.2 Set prediction loss<a hidden class="anchor" aria-hidden="true" href="#222-set-prediction-loss">#</a></h3>
<p>\(y\)랑 \(\hat{y}\) 를 가능한 1-1 매칭을 해보고, loss가 가장 적은 정책을 \(\hat{\sigma}\)라고 한다. 이는 Hungarian algorithm를 통해 사용.</p>
<p>\[\hat{\sigma}={\underset{\sigma\in S_{N}}{\arg\min}}\sum_{i}^{N}L_{match}(y_{i},\hat{y}_{\sigma(i)})\]</p>
<p>가장 최적의 \(\hat{\sigma}\)를 통해 답과의 loss를 구한다.</p>
<p>//[L_{Hungarian}(y,\hat{y})=\sum_{i=1}^N\left[-\log\hat{p}<em>{\hat{\sigma}(i)}(c_i)+1</em>{c_i\neq\emptyset}L_{box}(b_{i},\hat{b}_{\hat{\sigma}}(i))\right]//]</p>
<p>class가 맞으면, Loss가 작아지는 식의 Cross Entropy Loss + box의 차이가 작으면, loss가 작아지는 식이다.</p>
<p>bounding box loss</p>
<p>//[\lambda_{iou}L_{iou}(b_i,\hat{b}<em>{\sigma(i)})+ \lambda</em>{L1}\mid\mid b_{i}-\hat{b}_{\sigma(i)}\mid\mid_1//]</p>
<p>그냥 L1 loss만으로는 scale에 대해 영향을 많이 받으므로 generalized iou 도입.</p>
<h1 id="3-experiments">3. experiments<a hidden class="anchor" aria-hidden="true" href="#3-experiments">#</a></h1>
<p><img loading="lazy" src="https://github.com/ownvoy/ownogatari/assets/96481582/9cff582c-fa59-486d-b616-00b448bbf9ff" alt="image"  />
</p>
<p>DETR는 비슷 한수의 param과 FLOPS를 가진 Faster RCNN보다 성능이 좋은 것을 볼 수 있다. 다만, 작은 물체의 경우 Faster RCNN의 결과가 좋다.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://ownogatari.xyz/tags/cv/">CV</a></li>
    </ul>
<nav class="paginav">
  <a class="next" href="https://ownogatari.xyz/posts/textcnn/">
    <span class="title">Next »</span>
    <br>
    <span>TextCNN</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    <footer class="footer">
    
</footer>
</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css"
    integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous"
    referrerpolicy="no-referrer">

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js"
    integrity="sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY" crossorigin="anonymous"
    referrerpolicy="no-referrer" type="text/javascript"></script>

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js"
    integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous"
    referrerpolicy="no-referrer" type="text/javascript"></script>

<script type="text/javascript">
    document.addEventListener("DOMContentLoaded", function () {
        renderMathInElement(document.body, {
            delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "//[", right: "//]", display: true },
                { left: "$", right: "$", display: false },
                { left: "\\(", right: "\\)", display: false },
            ],
        });
    });
</script>
</body>

</html></body>

</html>
