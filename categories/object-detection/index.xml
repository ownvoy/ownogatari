<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Object Detection on 미래사회와 창의혁신인재</title>
    <link>https://ownogatari.xyz/categories/object-detection/</link>
    <description>Recent content in Object Detection on 미래사회와 창의혁신인재</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 23 Dec 2023 13:42:52 +0900</lastBuildDate><atom:link href="https://ownogatari.xyz/categories/object-detection/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Mask R-CNN</title>
      <link>https://ownogatari.xyz/posts/mask_r-cnn/</link>
      <pubDate>Sat, 23 Dec 2023 13:42:52 +0900</pubDate>
      
      <guid>https://ownogatari.xyz/posts/mask_r-cnn/</guid>
      <description>1. overview 1.1 objective Faster R-CNN 돌리는김에 segmentation 해보자. 1.2 background detection sementic segmentation instance segementation 대상 각각이 어떤 물체인지 각각이 어떤 클래스이고, instance를 구별x 각각이 어떤 클래스이고, instance를 구별 범위 bounding box마다 전체의 pixel마다 bounding box의 pixel마다 대표 모델 Faster R-CNN FCN Mask R-CNN , FCIS 예시 Fater R-CNN: sementic segmentation 못함. (RoIPooling이 한 뭉태기로 하니까, pixel에 대한 각각의 정보 소멸) FCN: instance segmentation 못함. (전체 픽셀별로 하니까) 2. main mask R-CNN은 RoI마다 mask(K class에 대해)를 내놓기에, instance segmentation 가능함.</description>
    </item>
    
    <item>
      <title>SDD</title>
      <link>https://ownogatari.xyz/posts/sdd/</link>
      <pubDate>Tue, 19 Dec 2023 00:00:00 +0000</pubDate>
      
      <guid>https://ownogatari.xyz/posts/sdd/</guid>
      <description>1. overview 1.1 objective multiple scale에 대해 다뤄 보자. (큰 물체, 작은 물체) \(\Rightarrow\) 장점: low resolution에 대한 문제를 해결 \(\Rightarrow\) 방법: 여러 개의 conv layer 도입
different shape에 대해 다뤄 보자. (박스 형태, 2:1, 1:1) \(\Rightarrow\) 장점: 다양한 형태의 객체 검출 \(\Rightarrow\) 방법: 박스 형태 다양하게
1.2 background YOLO YOLO 같은 경우 feature map이 \(7\times7\)짜리 1개이다. box개수는 각 cell마다 2개 있어서 총 98개이다.
2. main 2.1 architecture pretrained model + convolutional layer 논문에서는 VGG를 pretrained model로 사용</description>
    </item>
    
    <item>
      <title>R-FCN</title>
      <link>https://ownogatari.xyz/posts/r-fcn/</link>
      <pubDate>Thu, 23 Nov 2023 00:00:00 +0000</pubDate>
      
      <guid>https://ownogatari.xyz/posts/r-fcn/</guid>
      <description>1. overview 1.1 objective translation invariance 문제를 해결해보자. 모델을 fully convolutional 하게 만들어보자. 1.2 Background translational invariance vs translational variance translational invariance의 정의 positional invariance(translation invariance): 위치가 변하여도 결과가 똑같아야함 = 위치가 영향을 주지 않음 image classification에서의 주요 과제
cnn은 translational invaraince하다.
weight sharing convolutiona filter를 활용한 계산은 원래 translational equivariance(translational variance)함. 층이 깊어질 수록 tralational invariance가 됨. 그 이유는 계속 같은 필터를 써서(weight sharing) max pooling max pooling 역시 translational invariance한 연산 cnn은 어떤 위치에 사물이 있어도 잘 classify한다.</description>
    </item>
    
  </channel>
</rss>
